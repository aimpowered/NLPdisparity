{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3060\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] ='0'\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import copy\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from docx import Document\n",
    "import os\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizerFast\n",
    "import torch.nn.functional as F\n",
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    Loader for benchmarking datasets to ensure universal formatting. To be used in conjunction with DyslexiaInjector.\n",
    "    ...\n",
    "    Attributes\n",
    "    ----------\n",
    "    path: str\n",
    "        Path to csv, txt or docx file of the data. In the case of CSV there should only be 1 column\n",
    "    data: list\n",
    "        A list of striings\n",
    "    dataset_name: str\n",
    "        Name of the dataset that is used when saving the data\n",
    "        \n",
    "    Methods\n",
    "    -------\n",
    "    save_as_txt(path):\n",
    "        Saves data as a text file to specified path\n",
    "    save_as_csv(path):\n",
    "        Saves data as a csv file to specified path\n",
    "    get_data():\n",
    "        Returns data\n",
    "    create_deepcopy():\n",
    "        Returns a deep copy of the class instance\n",
    "    get_name():\n",
    "        returns name of the dataset (dataset_name)\n",
    "    \n",
    "    Usage\n",
    "    -------\n",
    "    >>> from datasets import load_dataset\n",
    "    >>> from DataLoader import DataLoader\n",
    "    >>> dataset_wmt_enfr = load_dataset(\"wmt14\",'fr-en', split='test')\n",
    "    >>> to_translate = []\n",
    "    >>> for i in range(len(dataset_wmt_enfr)):\n",
    "    >>>     to_translate.append(dataset_wmt_enfr[i]['translation']['en'])\n",
    "    >>> loader = DataLoader(data=to_translate, dataset_name=\"wmt14_enfr\")\n",
    "    >>> loader.save_as_txt(\"wmt14_enfr.txt\")\n",
    "    We can also use the text file to create a new DataLoader instance\n",
    "    >>> loader2 = DataLoader(path=\"wmt14_enfr.txt\", dataset_name=\"wmt14_enfr\")\n",
    "    \"\"\"\n",
    "    # Constructor\n",
    "    def __init__(self, path=None, data=None, dataset_name=\"\"):\n",
    "        self.dataset_name = dataset_name\n",
    "        if data is None and path is not None:\n",
    "            #check path to see if file is txt or csv\n",
    "            file_type = path.split(\".\")[-1]\n",
    "            if file_type == \"txt\":\n",
    "                self.data = self.parse_txt(path)\n",
    "                self.data = [self.fix_format(sentence) for sentence in self.data]\n",
    "            elif file_type == \"csv\":\n",
    "                self.data = pd.read_csv(path, header=None)\n",
    "                self.data = self.data[0].tolist()\n",
    "                #fix any formatting issues\n",
    "                self.data = [self.fix_format(sentence) for sentence in self.data]\n",
    "            elif file_type == \"docx\":\n",
    "                doc = Document(path)\n",
    "                self.data = [self.fix_format(paragraph.text) for paragraph in doc.paragraphs]\n",
    "            else:\n",
    "                raise Exception(\"Invalid file type\")\n",
    "        elif data is not None:\n",
    "            #check if data is a list or a df\n",
    "            if isinstance(data, list):\n",
    "                #format each sentence in data\n",
    "                self.data = [self.fix_format(sentence) for sentence in data]\n",
    "            else:\n",
    "                raise Exception(\"Invalid data type, please pass in a list of sentences\")\n",
    "        else:\n",
    "            raise Exception(\"Please pass in a path or data\")\n",
    "\n",
    "    def parse_txt(self, path):\n",
    "        output = []\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                output.append(self.fix_format(line))\n",
    "        return output\n",
    "                \n",
    "    def fix_format(self, sentence):\n",
    "        #remove spacing before punctuation\n",
    "        sentence = re.sub(r'\\s([?.!,\"](?:\\s|$))', r'\\1', sentence)\n",
    "        #replace any double spaces with single space\n",
    "        sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "        #remove any leading or trailing spaces\n",
    "        sentence = sentence.strip()\n",
    "        #make all quotes (german and french) english double quotes\n",
    "        sentence = re.sub(r'«|»|„|“', '\"', sentence)\n",
    "        #make all single quotes english single quotes\n",
    "        sentence = re.sub(r'‘|’', \"'\", sentence)\n",
    "        #make all french guillemets english double quotes\n",
    "        sentence = re.sub(r'‹|›', '\"', sentence)\n",
    "        #if sentence begins and ends with quotes and there are only two, remove them\n",
    "        if sentence[0] == '\"' and sentence[-1] == '\"' and sentence.count('\"') == 2:\n",
    "            sentence = sentence[1:-1]\n",
    "        elif sentence[0] == \"'\" and sentence[-1] == \"'\" and sentence.count(\"'\") == 2:\n",
    "            sentence = sentence[1:-1]\n",
    "        return sentence\n",
    "\n",
    "    def save_as_txt(self, path):\n",
    "        with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "            for sentence in self.data:\n",
    "                f.write(f\"{sentence}\\n\")\n",
    "        print(f\"Saved {self.dataset_name} to {path}\")\n",
    "        return\n",
    "    \n",
    "    def save_as_csv(self, path):\n",
    "        df = pd.DataFrame(self.data)\n",
    "        df.to_csv(path, index=False, header=False, encoding='utf-8')\n",
    "        print(f\"Saved {self.dataset_name} to {path}\")\n",
    "        return\n",
    "    \n",
    "    def save_as_docx(self, path):\n",
    "        document = Document()\n",
    "        for sentence in self.data:\n",
    "            document.add_paragraph(sentence)\n",
    "        document.save(path)\n",
    "        print(f\"Saved {self.dataset_name} to {path}\")\n",
    "        return\n",
    "\n",
    "    def get_data(self):\n",
    "        return self.data\n",
    "\n",
    "    def create_deepcopy(self):\n",
    "        return DataLoader(data=copy.deepcopy(self.data), dataset_name=self.dataset_name)\n",
    "        \n",
    "    def get_name(self):\n",
    "        return self.dataset_name\n",
    "\n",
    "    def get_number_of_sentences(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def get_number_of_words(self):\n",
    "        return sum([len(sentence.split()) for sentence in self.data])\n",
    "    \n",
    "    def get_number_of_letters(self):\n",
    "        #need to ensure we only count letters and not punctuation\n",
    "        return sum([len(re.sub(r'[^\\w\\s]','',sentence)) for sentence in self.data])\n",
    "\n",
    "    def edit_distance(reference_sentence, sentence):\n",
    "        \"\"\"\n",
    "        Returns the number of edits required to transform reference_sentence into sentence at word level\n",
    "        edits include insertions, deletions and substitutions\n",
    "        based on levenshtein distance\n",
    "        also returns a dictionary of substitutions, insertions and deletions\n",
    "        \"\"\"\n",
    "        substitutions = 0\n",
    "        insertions = 0\n",
    "        deletions = 0\n",
    "        substitution_dict = {}\n",
    "        insertion_dict = {}\n",
    "        deletion_dict = {}\n",
    "        #remove punctuation and split into words\n",
    "        sentence = re.sub(r'[^\\w\\s]','',sentence).lower().split()\n",
    "        reference_sentence = re.sub(r'[^\\w\\s]','',reference_sentence).lower().split()\n",
    "        #create matrix\n",
    "        matrix = np.zeros((len(reference_sentence)+1,len(sentence)+1))\n",
    "        #fill in first row and column\n",
    "        for i in range(len(reference_sentence)+1):\n",
    "            matrix[i][0] = i\n",
    "        for j in range(len(sentence)+1):\n",
    "            matrix[0][j] = j\n",
    "        #fill in rest of matrix\n",
    "        for i in range(1,len(reference_sentence)+1):\n",
    "            for j in range(1,len(sentence)+1):\n",
    "                if sentence[j-1] == reference_sentence[i-1]:\n",
    "                    matrix[i][j] = matrix[i-1][j-1]\n",
    "                else:\n",
    "                    matrix[i][j] = min(matrix[i-1][j-1], matrix[i-1][j], matrix[i][j-1])+1\n",
    "        #backtrack to find edits\n",
    "        i = len(reference_sentence)\n",
    "        j = len(sentence)\n",
    "        while i > 0 and j > 0:\n",
    "            if sentence[j-1] == reference_sentence[i-1]:\n",
    "                i -= 1\n",
    "                j -= 1\n",
    "            else:\n",
    "                if matrix[i][j] == matrix[i-1][j-1]+1:\n",
    "                    substitutions += 1\n",
    "                    if reference_sentence[i-1] not in substitution_dict:\n",
    "                        substitution_dict[reference_sentence[i-1]] = {sentence[j-1]:1}\n",
    "                    else:\n",
    "                        if sentence[j-1] not in substitution_dict[reference_sentence[i-1]]:\n",
    "                            substitution_dict[reference_sentence[i-1]][sentence[j-1]] = 1\n",
    "                        else:\n",
    "                            substitution_dict[reference_sentence[i-1]][sentence[j-1]] += 1\n",
    "                    i -= 1\n",
    "                    j -= 1\n",
    "                elif matrix[i][j] == matrix[i-1][j]+1:\n",
    "                    deletions += 1\n",
    "                    if reference_sentence[i-1] not in deletion_dict:\n",
    "                        deletion_dict[reference_sentence[i-1]] = 1\n",
    "                    else:\n",
    "                        deletion_dict[reference_sentence[i-1]] += 1\n",
    "                    i -= 1\n",
    "                elif matrix[i][j] == matrix[i][j-1]+1:\n",
    "                    insertions += 1\n",
    "                    if sentence[j-1] not in insertion_dict:\n",
    "                        insertion_dict[sentence[j-1]] = 1\n",
    "                    else:\n",
    "                        insertion_dict[sentence[j-1]] += 1\n",
    "                    j -= 1\n",
    "        while i > 0:\n",
    "            deletions += 1\n",
    "            if reference_sentence[i-1] not in deletion_dict:\n",
    "                deletion_dict[reference_sentence[i-1]] = 1\n",
    "            else:\n",
    "                deletion_dict[reference_sentence[i-1]] += 1\n",
    "            i -= 1\n",
    "        while j > 0:\n",
    "            insertions += 1\n",
    "            if sentence[j-1] not in insertion_dict:\n",
    "                insertion_dict[sentence[j-1]] = 1\n",
    "            else:\n",
    "                insertion_dict[sentence[j-1]] += 1\n",
    "            j -= 1\n",
    "        return substitutions, insertions, deletions, substitution_dict, insertion_dict, deletion_dict\n",
    "        \n",
    "    def get_edit_distance(self, reference):\n",
    "        \"\"\"\n",
    "        Returns the number of edits required to transform data into reference at word level\n",
    "        edits include insertions, deletions and substitutions\n",
    "        based on levenshtein distance\n",
    "        \"\"\"\n",
    "        if type(reference) == list:\n",
    "            substitutions = 0\n",
    "            insertions = 0\n",
    "            deletions = 0\n",
    "            all_sub = {}\n",
    "            all_ins = {}\n",
    "            all_del = {}\n",
    "            for i in range(len(self.data)):\n",
    "                sub, ins, dele, substitution_dict, insertion_dict, deletion_dict = DataLoader.edit_distance(reference[i], self.data[i], )\n",
    "                all_sub = self.combine_nested_dict(all_sub, substitution_dict)\n",
    "                all_ins = self.combine_dicts(all_ins, insertion_dict)\n",
    "                all_del = self.combine_dicts(all_del, deletion_dict)\n",
    "                substitutions += sub\n",
    "                insertions += ins\n",
    "                deletions += dele\n",
    "            return substitutions, insertions, deletions, all_sub, all_ins, all_del\n",
    "        elif type(reference) == DataLoader:\n",
    "            return self.get_edit_distance(reference.get_data())\n",
    "        else:\n",
    "            raise Exception(\"Invalid reference type, please pass in a list or DataLoader instance\")\n",
    "\n",
    "    def combine_nested_dict(self, dict1, dict2):\n",
    "        for key in dict2:\n",
    "            if key not in dict1:\n",
    "                dict1[key] = dict2[key]\n",
    "            else:\n",
    "                for key2 in dict2[key]:\n",
    "                    if key2 not in dict1[key]:\n",
    "                        dict1[key][key2] = dict2[key][key2]\n",
    "                    else:\n",
    "                        dict1[key][key2] += dict2[key][key2]\n",
    "        return dict1\n",
    "    \n",
    "    def combine_dicts(self, dict1, dict2):\n",
    "        for key in dict2:\n",
    "            if key not in dict1:\n",
    "                dict1[key] = dict2[key]\n",
    "            else:\n",
    "                dict1[key] += dict2[key]\n",
    "        return dict1\n",
    "\n",
    "    def get_bleue_score(self, reference):\n",
    "        #returns bleu score of the data against a reference\n",
    "        bleu = evaluate.load(\"bleu\")\n",
    "        if type(reference) == list:\n",
    "            return bleu.compute(predictions=self.data, references=reference)\n",
    "        elif type(reference) == DataLoader:\n",
    "            return bleu.compute(predictions=self.data, references=reference.get_data())\n",
    "        else:\n",
    "            raise Exception(\"Invalid reference type, please pass in a list or DataLoader instance\")\n",
    "\n",
    "    def get_wer(self, reference):\n",
    "        #returns wer score of the data against a reference\n",
    "        wer = evaluate.load(\"wer\")\n",
    "        if type(reference) == list:\n",
    "            return wer.compute(predictions=self.data, references=reference)\n",
    "        elif type(reference) == DataLoader:\n",
    "            return wer.compute(predictions=self.data, references=reference.get_data())\n",
    "        else:\n",
    "            raise Exception(\"Invalid reference type, please pass in a list or DataLoader instance\")\n",
    "\n",
    "    def get_bleurt_score(self, reference):\n",
    "        #returns bleurt score of the data against a reference\n",
    "        bleurt = evaluate.load(\"bleurt\")\n",
    "        if type(reference) == list:\n",
    "            return bleurt.compute(predictions=self.data, references=reference)\n",
    "        elif type(reference) == DataLoader:\n",
    "            return bleurt.compute(predictions=self.data, references=reference.get_data())\n",
    "        else:\n",
    "            raise Exception(\"Invalid reference type, please pass in a list or DataLoader instance\")\n",
    "            \n",
    "    def get_bert_score(self, reference):\n",
    "        #returns bert score of the data against a reference\n",
    "        bert = evaluate.load(\"bertscore\")\n",
    "        if type(reference) == list:\n",
    "            return bert.compute(predictions=self.data, references=reference, lang=\"fr\")\n",
    "        elif type(reference) == DataLoader:\n",
    "            return bert.compute(predictions=self.data, references=reference.get_data(), lang=\"fr\")\n",
    "        else:\n",
    "            raise Exception(\"Invalid reference type, please pass in a list or DataLoader instance\")\n",
    "\n",
    "    def similarity(self, embeddings_1, embeddings_2):\n",
    "        normalized_embeddings_1 = F.normalize(embeddings_1, p=2)\n",
    "        normalized_embeddings_2 = F.normalize(embeddings_2, p=2)\n",
    "        res = torch.matmul(\n",
    "            normalized_embeddings_1, normalized_embeddings_2.transpose(0, 1)\n",
    "        )\n",
    "        #only keep the diagonal values\n",
    "        res = res.diag()\n",
    "        return res\n",
    "\n",
    "    def get_LaBSE(self, reference, model=None, tokenizer=None):\n",
    "        \"\"\"\n",
    "        Returns the LaBSE similarity score of the data against a reference which is a l2 norm between the reference and target sentences score.\n",
    "        Score of 1 means the sentences are identical, closer to 0 means they are less similar semantically.\n",
    "        \"\"\"\n",
    "        if model is None:\n",
    "            model = BertModel.from_pretrained(\"setu4993/LaBSE\")\n",
    "        if tokenizer is None:\n",
    "            tokenizer = BertTokenizerFast.from_pretrained(\"setu4993/LaBSE\")\n",
    "        if type(reference) == list:\n",
    "            pass\n",
    "        elif type(reference) == DataLoader:\n",
    "            reference = reference.get_data()\n",
    "        else:\n",
    "            raise Exception(\"Invalid reference type, please pass in a list or DataLoader instance\")\n",
    "        target = self.data\n",
    "        reference_inputs = tokenizer(reference, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
    "        target_inputs = tokenizer(target, return_tensors=\"pt\", padding=True).to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            reference_outputs = model(**reference_inputs)\n",
    "            target_outputs = model(**target_inputs)\n",
    "        reference_embeddings = reference_outputs.pooler_output\n",
    "        target_embeddings = target_outputs.pooler_output\n",
    "        return self.similarity(reference_embeddings, target_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wmt14 (C:/Users/gerge/.cache/huggingface/datasets/wmt14/fr-en/1.0.0/2de185b074515e97618524d69f5e27ee7545dcbed4aa9bc1a4235710ffca33f4)\n"
     ]
    }
   ],
   "source": [
    "#need to loop through file directory\n",
    "aws_data_v1 = []\n",
    "aws_data_v2 = []\n",
    "for filename in os.listdir(\"to_test/v1/aws\"):\n",
    "    temp = DataLoader(path=\"to_test/v1/aws/\"+filename, dataset_name=\"aws_\"+filename)\n",
    "    aws_data_v1.append(temp)\n",
    "\n",
    "for filename in os.listdir(\"to_test/v2/aws\"):\n",
    "    temp = DataLoader(path=\"to_test/v2/aws/\"+filename, dataset_name=\"aws_\"+filename)\n",
    "    aws_data_v2.append(temp)\n",
    "\n",
    "azure_data_v1 = []\n",
    "for filename in os.listdir(\"to_test/v1/azure\"):\n",
    "    temp = DataLoader(path=\"to_test/v1/azure/\"+filename, dataset_name=\"azure_\"+filename)\n",
    "    azure_data_v1.append(temp)\n",
    "\n",
    "azure_data_v2 = []\n",
    "for filename in os.listdir(\"to_test/v2/azure\"):\n",
    "    temp = DataLoader(path=\"to_test/v2/azure/\"+filename, dataset_name=\"azure_\"+filename)\n",
    "    azure_data_v2.append(temp)\n",
    "\n",
    "google_data_v1 = []\n",
    "for filename in os.listdir(\"to_test/v1/google\"):\n",
    "    temp = DataLoader(path=\"to_test/v1/google/\"+filename, dataset_name=\"google_\"+filename)\n",
    "    google_data_v1.append(temp)\n",
    "\n",
    "google_data_v2 = []\n",
    "for filename in os.listdir(\"to_test/v2/google\"):\n",
    "    temp = DataLoader(path=\"to_test/v2/google/\"+filename, dataset_name=\"google_\"+filename)\n",
    "    google_data_v2.append(temp)\n",
    "\n",
    "gpt_data_v1 = []\n",
    "for filename in os.listdir(\"to_test/v1/gpt\"):\n",
    "    temp = DataLoader(path=\"to_test/v1/gpt/\"+filename, dataset_name=\"gpt_\"+filename)\n",
    "    gpt_data_v1.append(temp)\n",
    "\n",
    "gpt_data_v2 = []\n",
    "for filename in os.listdir(\"to_test/v2/gpt\"):\n",
    "    temp = DataLoader(path=\"to_test/v2/gpt/\"+filename, dataset_name=\"gpt_\"+filename)\n",
    "    gpt_data_v2.append(temp)\n",
    "\n",
    "from datasets import load_dataset\n",
    "dataset_wmt_enfr = load_dataset(\"wmt14\",'fr-en', split='test')\n",
    "to_translate_wmt14_en = []\n",
    "reference_wmt14_fr = []\n",
    "\n",
    "for i in range(len(dataset_wmt_enfr)):\n",
    "    to_translate_wmt14_en.append(dataset_wmt_enfr[i]['translation']['en'])\n",
    "    reference_wmt14_fr.append(dataset_wmt_enfr[i]['translation']['fr'])\n",
    "\n",
    "reference_corpus_fr = DataLoader(data=reference_wmt14_fr, dataset_name=\"wmt14_fr\")\n",
    "reference_corpus_en = DataLoader(data=to_translate_wmt14_en, dataset_name=\"wmt14_en\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertModel.from_pretrained(\"setu4993/LaBSE\")\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"setu4993/LaBSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(501153, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model to gpu\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_baseline = aws_data_v1[0].get_LaBSE(reference_corpus_en, model=model, tokenizer=tokenizer)\n",
    "#aws_baseline to pickle\n",
    "import pickle\n",
    "with open(\"aws_baseline_labse.pkl\", \"wb\") as f:\n",
    "    pickle.dump(aws_baseline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_french = reference_corpus_fr.get_LaBSE(reference_corpus_en, model=model, tokenizer=tokenizer)\n",
    "#reference_french to pickle\n",
    "with open(\"reference_french_labse.pkl\", \"wb\") as f:\n",
    "    pickle.dump(reference_french, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_baseline = google_data_v1[0].get_LaBSE(reference_corpus_en, model=model, tokenizer=tokenizer)\n",
    "#google_baseline to pickle\n",
    "with open(\"google_baseline_labse.pkl\", \"wb\") as f:\n",
    "    pickle.dump(google_baseline, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#azure baseline\n",
    "azure_baseline = azure_data_v1[0].get_LaBSE(reference_corpus_en, model=model, tokenizer=tokenizer)\n",
    "#azure_baseline to pickle\n",
    "with open(\"azure_baseline_labse.pkl\", \"wb\") as f:\n",
    "    pickle.dump(azure_baseline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_baseline = gpt_data_v1[0].get_LaBSE(reference_corpus_en, model=model, tokenizer=tokenizer)\n",
    "#gpt_baseline to pickle\n",
    "with open(\"gpt_baseline_labse.pkl\", \"wb\") as f:\n",
    "    pickle.dump(gpt_baseline, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aws baseline:  0.91499305\n",
      "azure baseline:  0.92010856\n",
      "google baseline:  0.9195048\n",
      "gpt baseline:  0.91543984\n",
      "reference french:  0.88630885\n"
     ]
    }
   ],
   "source": [
    "#get average of all the scores\n",
    "aws_baseline = np.average(aws_baseline.cpu().numpy())\n",
    "azure_baseline = np.average(azure_baseline.cpu().numpy())\n",
    "google_baseline = np.average(google_baseline.cpu().numpy())\n",
    "gpt_baseline = np.average(gpt_baseline.cpu().numpy())\n",
    "reference_french = np.average(reference_french.cpu().numpy())\n",
    "\n",
    "#print out results\n",
    "print(\"aws baseline: \", aws_baseline)\n",
    "print(\"azure baseline: \", azure_baseline)\n",
    "print(\"google baseline: \", google_baseline)\n",
    "print(\"gpt baseline: \", gpt_baseline)\n",
    "print(\"reference french: \", reference_french)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dyslexia_Research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
