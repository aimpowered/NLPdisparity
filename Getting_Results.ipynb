{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing API Results and Model Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will go over how to reproduce our results for the [Google API translation](#google-api-translation), [Azure translation](#azure-translation) and [AWS API translation](#aws-translation). For recreating model results section please click [here](#recreating-model-results). For a summary of all results please go to [bottom of the notebook](#summary-of-results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets\n",
    "%pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.cloud import translate\n",
    "import pickle\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "import requests, uuid, json\n",
    "import pandas as pd\n",
    "#need to set os environment variable with google applioation credentials\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"path/to/credentials.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting our datasets, I would recommend downloading them and loading them locally\n",
    "#these are from huggingface datasets\n",
    "dataset_wmt_enfr = load_dataset(\"wmt14\",'fr-en', split='test')\n",
    "dataset_wmt_ende = load_dataset(\"wmt16\",'de-en', split='test')\n",
    "\n",
    "print(dataset_wmt_ende[0]['translation']['de'])\n",
    "print(dataset_wmt_enfr[0]['translation']['fr'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our corpuses in arrays (simpler view)\n",
    "to_translate_wmt14_en = []\n",
    "to_translate_wmt16_en = []\n",
    "\n",
    "for i in range(len(dataset_wmt_enfr)):\n",
    "    to_translate_wmt14_en.append(dataset_wmt_enfr[i]['translation']['en'])\n",
    "for i in range(len(dataset_wmt_ende)):\n",
    "    to_translate_wmt16_en.append(dataset_wmt_ende[i]['translation']['en'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google API Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our translation function from google api advanced translation v3\n",
    "def translate_text(source_lang=\"en-US\", target_lang=\"fr\", text=\"YOUR_TEXT_TO_TRANSLATE\", project_id=\"YOUR_PROJECT_ID\"):\n",
    "    \"\"\"Translating Text.\"\"\"\n",
    "    #this uses google credentials from the environment variable\n",
    "    client = translate.TranslationServiceClient()\n",
    "\n",
    "    location = \"global\"\n",
    "\n",
    "    parent = f\"projects/{project_id}/locations/{location}\"\n",
    "\n",
    "    # Translate text from English to French\n",
    "    # Detail on supported types can be found here:\n",
    "    # https://cloud.google.com/translate/docs/supported-formats\n",
    "    response = client.translate_text(\n",
    "        request={\n",
    "            \"parent\": parent,\n",
    "            \"contents\": [text],\n",
    "            \"mime_type\": \"text/plain\",  # mime types: text/plain, text/html\n",
    "            \"source_language_code\": source_lang, #was \"en-US\"\n",
    "            \"target_language_code\": target_lang, #was \"fr\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return response.translations[0].translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our candidate corpuses and reference corpuses\n",
    "candidate_wmt14_fr_google = []\n",
    "candidate_wmt16_de_google = []\n",
    "reference_wmt14_fr = []\n",
    "reference_wmt16_de = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this next block will take time as we are making api calls\n",
    "#is it possible to send batch requests?\n",
    "\n",
    "for i in range(len(to_translate_wmt14_en)):\n",
    "    candidate_wmt14_fr_google.append(translate_text(target_lang=\"fr\", text=to_translate_wmt14_en[i]))\n",
    "    reference_wmt14_fr.append(dataset_wmt_enfr[i]['translation']['fr'])\n",
    "    #log progress\n",
    "    if i % 100 == 0:\n",
    "        print(i + \" out of \" + len(to_translate_wmt14_en) + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as above for wmt16\n",
    "for i in range(len(to_translate_wmt16_en)):\n",
    "    candidate_wmt16_de_google.append(translate_text(target_lang=\"de\", text=to_translate_wmt16_en[i]))\n",
    "    reference_wmt16_de.append(dataset_wmt_ende[i]['translation']['de'])\n",
    "    #log progress\n",
    "    if i % 100 == 0:\n",
    "        print(i + \" out of \" + len(to_translate_wmt16_en) + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get bleu from evaluate and get scores\n",
    "bleu_wmt14_fr_google = evaluate.bleu(candidate_wmt14_fr, reference_wmt14_fr)\n",
    "bleu_wmt16_de_google = evaluate.bleu(candidate_wmt16_de, reference_wmt16_de)\n",
    "\n",
    "#print bleu scores\n",
    "print(\"BLEU score for WMT14 English to French: \", bleu_wmt14_fr)\n",
    "print(\"BLEU score for WMT16 English to German: \", bleu_wmt16_de)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our azure translation function\n",
    "def azure_translate_text(text, target_language):\n",
    "    #the APi used https://azure.microsoft.com/en-us/products/cognitive-services/translator/\n",
    "    #the free tier is sufficient for our needs\n",
    "    key = \"your key\" #THIS MUST BE CHANGED  \n",
    "    endpoint = \"https://api.cognitive.microsofttranslator.com/\"\n",
    "    location = \"enter location\" #THIS MUST BE CHANGED\n",
    "\n",
    "    path = '/translate'\n",
    "    constructed_url = endpoint + path\n",
    "\n",
    "    params = {\n",
    "        'api-version': '3.0',\n",
    "        'from': 'en', #can be changed in needed\n",
    "        'to': target_language\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': key,\n",
    "        'Ocp-Apim-Subscription-Region': location,\n",
    "        'Content-type': 'application/json',\n",
    "        'X-ClientTraceId': str(uuid.uuid4())\n",
    "    }\n",
    "\n",
    "    body = [{\n",
    "        'text': text\n",
    "    }]\n",
    "    request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
    "    response = request.json()\n",
    "\n",
    "    return response[0]['translations'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our candidate corpuses\n",
    "candidate_wmt14_fr_azure = []\n",
    "# reference_wmt14_fr = []\n",
    "\n",
    "for i in range(len(to_translate_wmt14_en)):\n",
    "    candidate_wmt14_fr_azure.append(azure_translate_text(to_translate_wmt14_en[i], 'fr'))\n",
    "    #reference_wmt14_fr.append(dataset_wmt_enfr[i]['translation']['fr'])\n",
    "    #log progress\n",
    "    if i % 100 == 0:\n",
    "        print(i + \" out of \" + len(to_translate_wmt14_en) + \" done\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as above for wmt16\n",
    "candidate_wmt16_de_azure = []\n",
    "# reference_wmt16_de = []\n",
    "for i in range(len(to_translate_wmt16_en)):\n",
    "    candidate_wmt16_de_azure.append(azure_translate_text(to_translate_wmt16_en[i], 'de'))\n",
    "    #reference_wmt16_de.append(dataset_wmt_ende[i]['translation']['de'])\n",
    "    #log progress\n",
    "    if i % 100 == 0:\n",
    "        print(i + \" out of \" + len(to_translate_wmt16_en) + \" done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get our bleu scores\n",
    "bleu_wmt14_fr_azure = evaluate.bleu(candidate_wmt14_fr_azure, reference_wmt14_fr)\n",
    "bleu_wmt16_de_azure = evaluate.bleu(candidate_wmt16_de_azure, reference_wmt16_de)\n",
    "\n",
    "#print bleu scores\n",
    "print(\"BLEU score for WMT14 English to French: \", bleu_wmt14_fr_azure)\n",
    "print(\"BLEU score for WMT16 English to German: \", bleu_wmt16_de_azure)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AWS Translation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section is actually m,ostly done on AWS, so we will just go over how to reproduce the results. We utilize the batch translation on amazon so we must store our data in an S3 bucket."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must set up our data in a batch translation friendly format. For our case we simply convert our data into an excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to translate arrays to df\n",
    "#we will put all to translate arrays in seperate columns in same df\n",
    "df_to_translate = pd.DataFrame()\n",
    "df_to_translate['wmt14_en'] = to_translate_wmt14_en\n",
    "df_to_translate['wmt16_en'] = to_translate_wmt16_en\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we save as an excel file\n",
    "df.to_excel(\"to_translate.xlsx\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One we saved the file. We must create a new bucket and upload the excel file to our S3 bucket. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recommend viewing [this](https://www.youtube.com/watch?v=uS_2GJh3TsY&t=542s) video for a step by step guide on how to complete this task.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load back in our  data and complete similar steps as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in xlsx file thgat was translated\n",
    "df_translated = pd.read_excel(\"translated.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we create our candidate corpuses\n",
    "candidate_wmt14_fr_translated_aws = df_translated['wmt14_fr_aws'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same as above\n",
    "candidate_wmt16_de_translated_aws = df_translated['wmt16_de'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate bleu scores\n",
    "\n",
    "bleu_wmt14_fr_translated_aws = evaluate.bleu(candidate_wmt14_fr_translated_aws, reference_wmt14_fr)\n",
    "bleu_wmt16_de_translated_aws = evaluate.bleu(candidate_wmt16_de_translated_aws, reference_wmt16_de)\n",
    "\n",
    "#print bleu scores\n",
    "print(\"BLEU score for WMT14 English to French: \", bleu_wmt14_fr_translated_aws)\n",
    "print(\"BLEU score for WMT16 English to German: \", bleu_wmt16_de_translated_aws)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreating Model Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this we will need facebook's fairseq library. We will clone the repo and cd into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%git clone https://github.com/pytorch/fairseq.git\n",
    "%cd fairseq/\n",
    "%pip install --editable ./\n",
    "%pip install sacremoses\n",
    "%pip install subword-nmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I would recommend using a torch with cuda support\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 \n",
    "This model can be found [here](https://arxiv.org/abs/1705.03122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our first model is for wmt14 en-fr from fairseq. It is a convolutional seq2seq model\n",
    "#the paper can be found here https://arxiv.org/abs/1705.03122\n",
    "m1_en2fr = torch.hub.load('pytorch/fairseq', 'conv.wmt14.en-fr',\n",
    "                       tokenizer='moses', bpe='subword_nmt')\n",
    "m1_en2fr.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_en2fr.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our candidate corpuse\n",
    "candidate_wmt14_fr_m1 = []\n",
    "#reference_wmt14_fr = []\n",
    "\n",
    "for i in range(len(to_translate_wmt14_en)):\n",
    "    candidate_wmt14_fr_m1.append(m1_en2fr.translate(to_translate_wmt14_en[i]))\n",
    "    #reference_wmt14_fr.append(dataset_wmt_enfr[i]['translation']['fr'])\n",
    "    #log progress\n",
    "    if i % 100 == 0:\n",
    "        print(i + \" out of \" + len(to_translate_wmt14_en) + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate bleu score\n",
    "bleu_wmt14_fr_m1 = evaluate.bleu(candidate_wmt14_fr_m1, reference_wmt14_fr)\n",
    "\n",
    "#print bleu score\n",
    "print(\"BLEU score for WMT14 English to French: \", bleu_wmt14_fr_m1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2\n",
    "This model can be found [here](https://arxiv.org/abs/1806.00187)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a seq2dew with fast training abilities\n",
    "\n",
    "m2_en2fr = torch.hub.load('pytorch/fairseq', 'transformer.wmt14.en-fr',\n",
    "                       tokenizer='moses', bpe='subword_nmt')\n",
    "m2_en2fr.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_en2fr.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our candidate corpuse\n",
    "candidate_wmt14_fr_m2 = []\n",
    "#reference_wmt14_fr = []\n",
    "\n",
    "for i in range(len(to_translate_wmt14_en)):\n",
    "    candidate_wmt14_fr_m2.append(m2_en2fr.translate(to_translate_wmt14_en[i]))\n",
    "    #reference_wmt14_fr.append(dataset_wmt_enfr[i]['translation']['fr'])\n",
    "    #log progress\n",
    "    if i % 100 == 0:\n",
    "        print(i + \" out of \" + len(to_translate_wmt14_en) + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate bleu score\n",
    "bleu_wmt14_fr_m2 = evaluate.bleu(candidate_wmt14_fr_m2, reference_wmt14_fr)\n",
    "\n",
    "#print bleu score\n",
    "print(\"BLEU score for WMT14 English to French: \", bleu_wmt14_fr_m2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was also trained for wmt16 en to de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_en2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt16.en-de',\n",
    "                       tokenizer='moses', bpe='subword_nmt')\n",
    "m2_en2de.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_en2de.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create our candidate corpuse\n",
    "candidate_wmt16_de_m2 = []\n",
    "#reference_wmt16_de = []\n",
    "\n",
    "for i in range(len(to_translate_wmt16_en)):\n",
    "    candidate_wmt16_de_m2.append(m2_en2de.translate(to_translate_wmt16_en[i]))\n",
    "    #reference_wmt16_de.append(dataset_wmt_ende[i]['translation']['de'])\n",
    "    #log progress\n",
    "    if i % 100 == 0:\n",
    "        print(i + \" out of \" + len(to_translate_wmt16_en) + \" done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate bleu score\n",
    "bleu_wmt16_de_m2 = evaluate.bleu(candidate_wmt16_de_m2, reference_wmt16_de)\n",
    "\n",
    "#print bleu score\n",
    "print(\"BLEU score for WMT16 English to German: \", bleu_wmt16_de_m2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of Results\n",
    "An ouput for all the data in one spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summerizing our results\n",
    "\n",
    "print(\"BLEU score for Google API on WMT14 English to French: \", bleu_wmt14_fr_google)\n",
    "print(\"BLEU score for Google API on WMT16 English to German: \", bleu_wmt16_de_google)\n",
    "\n",
    "print(\"BLEU score for Azure API on WMT14 English to French: \", bleu_wmt14_fr_azure)\n",
    "print(\"BLEU score for Azure API on WMT16 English to German: \", bleu_wmt16_de_azure)\n",
    "\n",
    "print(\"BLEU score for AWS API on WMT14 English to French: \", bleu_wmt14_fr_translated_aws)\n",
    "print(\"BLEU score for AWS API on WMT16 English to German: \", bleu_wmt16_de_translated_aws)\n",
    "\n",
    "print(\"BLEU score for Fairseq Convolutional (Model 1) on WMT14 English to French: \", bleu_wmt14_fr_m1)\n",
    "\n",
    "print(\"BLEU score for Fairseq Transformer (Model 2) on WMT14 English to French: \", bleu_wmt14_fr_m2)\n",
    "print(\"BLEU score for Fairseq Transformer (Model 2) on WMT16 English to German: \", bleu_wmt16_de_m2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
